# Tibetian Translation Aid
Exploring Trade-Offs of LLMs for Tibetan

# Initial TO-DOs:

[ ] - Read [PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models](https://arxiv.org/pdf/2309.12109) and create notes in notes directory.

[ ] - Read [Teaching Large Language Models an Unseen Language on the Fly](https://arxiv.org/html/2402.19167v1)  and create notes in notes directory.

[ ] - Download data to this repository

[ ] - Create fine-tuned GPT-4 Model.

[ ] - Choose and download open-source models.

[ ] - Get comparision metrics on cost and metrics

Should be done by end of June

